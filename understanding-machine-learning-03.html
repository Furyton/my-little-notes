<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>Notes - Understanding Machine Learning 03</title>
        
            <meta name="author" content="Shiguang Wu">
        
        
        <link rel="shortcut icon" type="image/x-icon" href="./images/captain-america-shield.jpg" />
        <link rel="stylesheet" href="./css/default.css" crossorigin="anonymous">
        <link rel="stylesheet" href="./css/blog.css" crossorigin="anonymous">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous">

        <!-- The loading of KaTeX is deferred to speed up page rendering -->
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js" integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY" crossorigin="anonymous"></script>
    
        <!-- To automatically render math in text elements, include the auto-render extension: -->
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="./">My back yard</a>
            </div>
            <div id="navigation">
                <a href="./">Home</a>
                <!-- <a href="/archive.html">Archive</a> -->
                <a href="./about.html">About</a>
            </div>
        </div>

        <div id="content">
            <h1>Understanding Machine Learning 03</h1>

            <div class="info">
    Posted on March 11, 2022
    
        by Shiguang Wu
    
</div>
<div class="info">
    
    Tags: <a title="All pages tagged 'UML'." href="./tags/UML.html">UML</a>
    
</div>

<h2 id="uniform-convergence">Uniform Convergence</h2>
<p>Before, the way of choosing <span class="math inline">\(m_H\)</span> and the effect of <span class="math inline">\(\delta\)</span> was related to the learner. However, we can borrow the concept of uniform convergence from analysis to make it independent of what learner you use.</p>
<p>here, we can treat <span class="math inline">\(L_S(h)\)</span> as <span class="math inline">\(\sum_i^nf_i(x)\)</span> since they are both intermediate vals during the convergence, and <span class="math inline">\(L_D(h)\)</span> to be the final end</p>
<h3 id="def-epsilon-representative-sample">def <span class="math inline">\(\epsilon\)</span>-representative sample</h3>
<p><span class="math inline">\(S\)</span> is <span class="math inline">\(\epsilon\)</span>-representation sample (w.r.t domain, <span class="math inline">\(H\)</span>, <span class="math inline">\(l\)</span> and <span class="math inline">\(D\)</span>) if</p>
<p><span class="math display">\[
\forall h\in\mathcal{H},\, |L_S(h)-L_D(h)|\le \epsilon
\]</span></p>
<p>lemma</p>
<p>if S is <span class="math inline">\(\frac{\epsilon}{2}\)</span>-representative, then <span class="math inline">\(\forall h_S\in\argmin_{h\in\mathcal{H}}L_S(h)\)</span></p>
<p><span class="math display">\[
L_D(h_S)\le \min_{h\in\mathcal{H}}L_D(h)+\epsilon
\]</span></p>
<p>through this lemma, we can immediately have</p>
<p><span class="math inline">\(S\)</span> is <span class="math inline">\(\frac{\epsilon}{2}\)</span>-representative with prob <span class="math inline">\(1-\delta\)</span> <span class="math inline">\(\implies\)</span> Agnostic PAC learnability</p>
<h3 id="def-uniform-convergence">def uniform convergence</h3>
<p>H has the uniform convergence <span class="math inline">\(\coloneqq\)</span> exists a func <span class="math inline">\(m_H^{UC}(\epsilon, \delta)\)</span>, for every <span class="math inline">\(D\)</span>, if <span class="math inline">\(|S|\gt m_H^{UC}\)</span> then with <span class="math inline">\(1-\delta\)</span> prob, it is <span class="math inline">\(\epsilon\)</span>-representative</p>
<p>It seems stronger than the original agnostic PAC, just like the rel between uniform conv and normal conv in analysis. normal conv only cares the situation in a certain area (here the decider generated by the learner), while uni conv holds on the whole area (all <span class="math inline">\(h\in\mathcal{H}\)</span>)</p>
<h4 id="corallary">corallary</h4>
<p><span class="math inline">\(m_H\le m_H^{UC}\)</span> if <span class="math inline">\(H\)</span> has the uni conv property</p>
<h2 id="situation-of-the-finite-h-class">situation of the finite H class</h2>
<p>need to find <span class="math inline">\(m\)</span>, so that</p>
<p><span class="math display">\[
D^m(\{S:\forall h\in \mathcal{H},|L_S(h)-L_D(h)|\le\epsilon\})\ge 1-\delta
\]</span></p>
<p>and we may convert it into a more familiar form (convenient for using inequalities)</p>
<p><span class="math display">\[
D^m(\{S:\exists h\in \mathcal{H},|L_S(h)-L_D(h)|\gt\epsilon\})\lt \delta
\]</span></p>
<p>using union bound and Hodeffing inequalities (note that <span class="math inline">\(L_D(h)=\mathbb{E}_{S\sim D^m}(L_S(h))\)</span>), we have</p>
<p><span class="math display">\[
LHS\le\sum_{h\in\mathcal{H}}2exp(-2m\epsilon^2)
\]</span></p>
<p>as a corollary, we have the upper bound for finite hypothesis class which is agnostic PAC learnable</p>
<p><span class="math display">\[
m_H^{UC}(\epsilon,\delta)\le\left\lceil\frac{log(2|\mathcal{H}|/\delta)}{2\epsilon^2}\right\rceil
\]</span></p>
<p>summary:</p>
<blockquote>
<p>if uni conv holds, then in most cases, the empirical risks of h in H will faithfully represent their true risks</p>
</blockquote>
<hr />
<p>exercises</p>
<ul>
<li>4.1</li>
</ul>
<ol type="1">
<li><p><span class="math inline">\(\forall \epsilon,\delta\gt 0,\exists m(\epsilon,\delta)\,s.t.\)</span>
<span class="math display">\[
\forall m\ge m(\epsilon,\delta),\,\mathcal{P}_{S\sim D^m}[L_D(A(S))\gt\epsilon]\lt\delta\]</span></p></li>
<li><p><span class="math inline">\(\lim_{m\to \infty}\mathbb{E}_{S\sim D^m}[L_D(A(S))]=0\)</span></p></li>
</ol>
<p>1 <span class="math inline">\(\iff\)</span> 2</p>

<hr>

<nav class="info">
    <a href="./">Home</a>
    <a href="mailto:furyton@outlook.com">Email Me</a>
</nav>
        </div>
        <div id="footer">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>, this site project is located at <a href="https://github.com/Furyton/my-little-notes">Github</a>
        </div>
    </body>
</html>
